# VTuber AI LLM é…ç½®æ–‡ä»¶

# æ¨¡å‹é…ç½®
models:
  llm:
    model_path: "models/Qwen3-8B"  # ç›¸å°è·¯å¾‘
    device: "cuda"
    
    # ğŸ”¥ æ–°å¢ï¼šè¼‰å…¥æ¨¡å¼é¸æ“‡
    loading_mode: "transformers"    # "transformers" æˆ– "vllm"
    
    # Transformers æ¨¡å¼é…ç½®
    quantization: "4bit"         # æ”¹ç‚º4bité‡åŒ–ç²å¾—æ›´å¥½æ€§èƒ½
    optimization_mode: "auto"    # auto, deepspeed, 8bit, fp16
    max_length: 4096

    # ğŸ”¥ å¤šGPUé…ç½®
    multi_gpu:
      enabled: true
      primary_gpus: 4          # ä¸»æ¨¡å‹ä½¿ç”¨çš„GPUæ•¸é‡
      embedding_gpu: 4         # åµŒå…¥æ¨¡å‹ä½¿ç”¨çš„GPUç´¢å¼•
      memory_optimization: true
      auto_device_map: true

    # vLLM æ¨¡å¼é…ç½®
    vllm:
      # GPU é…ç½®
      tensor_parallel_size: "auto"     # "auto" æˆ–æŒ‡å®šæ•¸é‡ï¼Œå¦‚ 4
      pipeline_parallel_size: 1        # ç®¡é“ä¸¦è¡Œå¤§å°
      gpu_memory_utilization: 0.8     # GPUè¨˜æ†¶é«”ä½¿ç”¨ç‡ (0.7-0.95)
      swap_space: 0.5                    # äº¤æ›ç©ºé–“å¤§å° (GB)
      
      # æ¨¡å‹é…ç½®
      max_model_len: 8192              # æ¨¡å‹æœ€å¤§é•·åº¦ (
      max_num_seqs: 128                # æœ€å¤§ä¸¦ç™¼åºåˆ—æ•¸ (é™ä½åˆ°128)
      max_num_batched_tokens: null     # æœ€å¤§æ‰¹æ¬¡tokenæ•¸ (nullç‚ºè‡ªå‹•)
      
      # æ€§èƒ½é…ç½®
      quantization: "8bit"              # null, "awq", "gptq", "fp8"
      dtype: "half"                    # "half", "float", "bfloat16"
      kv_cache_dtype: "auto"           # "auto", "fp8", "fp16"
      
      # å¼•æ“é…ç½®
      worker_use_ray: false            # æ˜¯å¦ä½¿ç”¨Ray
      engine_use_ray: false            # å¼•æ“æ˜¯å¦ä½¿ç”¨Ray
      disable_log_stats: false         # ç¦ç”¨çµ±è¨ˆæ—¥èªŒ
      disable_log_requests: true       # ç¦ç”¨è«‹æ±‚æ—¥èªŒ
      
      # èª¿åº¦å™¨é…ç½®
      max_paddings: 256                # æœ€å¤§å¡«å……æ•¸é‡
    
    # å„ªåŒ–çš„ç”Ÿæˆåƒæ•¸
    temperature: 0.75
    top_p: 0.8
    top_k: 40
    repetition_penalty: 1.15
    no_repeat_ngram_size: 3
    length_penalty: 1.0
    
  embedding:
    model_path: "models/Qwen3-Embedding-0.6B"
    device: "cuda"
    batch_size: 32
    max_length: 512
    # ğŸ”¥ æ–°å¢ï¼šåµŒå…¥æ¨¡å‹å¤šGPUé…ç½®
    multi_gpu:
      preferred_gpu: 4         # å„ªå…ˆä½¿ç”¨çš„GPU
      fallback_auto: true      # è‡ªå‹•å›é€€

# RAG é…ç½®
rag:
  vector_db:
    type: "chroma"
    persist_directory: "./scrpitsV2/LLM/data/vectordb"
    collection_name: "vtuber_knowledge"
  
  retrieval:
    top_k: 5
    similarity_threshold: 0.4
    chunk_size: 1000
    chunk_overlap: 200
  
  # RAG æª¢ç´¢å…§å®¹é…ç½®
  content_types:
    dialogue_examples: true           # å°è©±ç¯„ä¾‹
    emotional_expressions: true      # æƒ…æ„Ÿè¡¨é”
    comfort_phrases: true            # å®‰æ…°è©±èª
    intimate_interactions: true      # è¦ªå¯†äº’å‹•
    personality_traits: true         # äººæ ¼ç‰¹å¾µ
    
  retrieval_strategy:
    emotion_weighted: true           # æƒ…æ„ŸåŠ æ¬Šæª¢ç´¢
    intent_focused: true             # æ„åœ–èšç„¦æª¢ç´¢
    intimacy_filtered: true          # è¦ªå¯†åº¦éæ¿¾
    context_aware: true              # ä¸Šä¸‹æ–‡æ„ŸçŸ¥

# VTuber å›æ‡‰é…ç½® (è§’è‰²è¨­å®šå®Œå…¨ç”± core.json ç®¡ç†)
vtuber:
  response:
    max_tokens: 150     # èª¿æ•´ç‚º150 â‰ˆ 75-100 ä¸­æ–‡å­—
    min_tokens: 25      # èª¿æ•´ç‚º25 â‰ˆ 12-18 ä¸­æ–‡å­—

    stream: true
    add_personality: true
    # å›æ‡‰éæ¿¾è¨­ç½®
    filter_repetition: true
    filter_incomplete: true
    max_sentence_repeat: 1
    
    # æ™ºæ…§æ›è¡Œè¨­ç½®
    enable_line_break: true             # å•Ÿç”¨æ™ºæ…§æ›è¡Œè™•ç†
    
    # äººæ€§åŒ–å°è©±ç¯€å¥è¨­ç½®
    enable_typing_simulation: true      # å•Ÿç”¨æ‰“å­—æ¨¡æ“¬
    typing_speed: 1.2                   # æ¯è¡Œé–“éš”æ™‚é–“ï¼ˆç§’ï¼‰
    typing_speed_variation: 0.3         # æ™‚é–“è®ŠåŒ–å¹…åº¦ï¼ˆÂ±ç§’ï¼‰
    typing_min_delay: 0.5               # æœ€å°é–“éš”æ™‚é–“ï¼ˆç§’ï¼‰
    typing_max_delay: 2.0               # æœ€å¤§é–“éš”æ™‚é–“ï¼ˆç§’ï¼‰
    
    # ç°¡ç¹è½‰æ›è¨­ç½®
    enable_traditional_chinese: true    # å•Ÿç”¨ç°¡é«”è½‰ç¹é«”
    opencc_config: "s2twp.json"        # OpenCC é…ç½®æ–‡ä»¶ï¼šs2twp.json (ç°¡é«”åˆ°ç¹é«”+è©å½™è½‰æ›) 
    
    # æƒ…æ„Ÿé©æ‡‰æ€§å›æ‡‰
    emotional_adaptation:
      enabled: true
      comfort_mode: true              # å®‰æ…°æ¨¡å¼
      excitement_sharing: true        # æƒ…ç·’å…±é³´
      gentle_correction: true         # æº«æŸ”ç³¾æ­£
      
    # è¦ªå¯†åº¦æ„ŸçŸ¥å›æ‡‰
    intimacy_awareness:
      enabled: true
      progressive_closeness: true     # æ¼¸é€²å¼è¦ªå¯†
      appropriate_boundaries: true    # é©ç•¶é‚Šç•Œ
      natural_affection: true         # è‡ªç„¶æƒ…æ„Ÿè¡¨é”

# STT èªéŸ³è­˜åˆ¥é…ç½®
stt:
  enabled: false                       # ç¦ç”¨ STT èªéŸ³è­˜åˆ¥ (Discord Bot ä¸éœ€è¦)
  auto_response: false                 # è‡ªå‹•å›æ‡‰èªéŸ³è¼¸å…¥ï¼ˆfalseè¡¨ç¤ºåƒ…é è¦½ï¼Œéœ€æ‰‹å‹•ç™¼é€ï¼‰
  auto_stop_after_transcription: true  # æ”¶åˆ°è½‰éŒ„çµæœå¾Œè‡ªå‹•åœæ­¢ç›£è½ï¼ˆè¨­ç‚ºtrueä»¥é¿å…æŒçºŒæ”¶éŸ³ï¼‰
  
  # èªéŸ³è½‰æ–‡å­—é…ç½® - ä¿®æ­£ç‚ºSTT.pyæœŸæœ›çš„æ ¼å¼
  language: "zh-TW"                    # è­˜åˆ¥èªè¨€ï¼šzh-TW, zh-CN, zh, en, ja, ko
  model: "base"                        # èªéŸ³è­˜åˆ¥æ¨¡å‹ï¼štiny, base, small, medium, large
  
  # èªéŸ³æª¢æ¸¬é…ç½®
  silero_sensitivity: 0.4              # Silero VAD éˆæ•åº¦ (0.1-1.0) - RealtimeSTTé è¨­
  webrtc_sensitivity: 3                # WebRTC VAD éˆæ•åº¦ (0-3) - RealtimeSTTé è¨­
  post_speech_silence_duration: 0.6    # èªéŸ³çµæŸå¾ŒéœéŸ³æ™‚é•·ï¼ˆç§’ï¼‰
  min_length_of_recording: 0.5         # æœ€çŸ­éŒ„éŸ³æ™‚é•·ï¼ˆç§’ï¼‰
  
  # GPUé…ç½®
  use_gpu: true                        # ä½¿ç”¨GPUåŠ é€Ÿ
  gpu_device_index: 0                  # GPUè¨­å‚™ç´¢å¼•
  
  # å³æ™‚è½‰éŒ„é…ç½®
  enable_realtime_transcription: false # å•Ÿç”¨å³æ™‚è½‰éŒ„ï¼ˆå…ˆé—œé–‰é¿å…è¤‡é›œæ€§ï¼‰
  realtime_processing_pause: 0.2       # å³æ™‚è™•ç†é–“éš”ï¼ˆç§’ï¼‰
  realtime_model_type: "tiny"          # å³æ™‚è½‰éŒ„æ¨¡å‹
  
  # OpenCCç°¡è½‰ç¹é…ç½®
  enable_opencc: true                  # å•Ÿç”¨OpenCCè½‰æ›
  opencc_config: "s2twp.json"          # ç°¡é«”è½‰ç¹é«”ï¼ˆå°ç£ç”¨è©ï¼‰
  
  # å…¶ä»–é…ç½®
  sample_rate: 16000                   # æ¡æ¨£ç‡
  beam_size: 5                         # æŸæœç´¢å¤§å°

# èªç¾©åˆ†æèˆ‡æƒ…æ„Ÿç†è§£é…ç½®
semantic_analysis:
  enabled: true
  description: "éœ²è¥¿äºæ›´å¥½åœ°ç†è§£ç”¨æˆ¶çš„æƒ…æ„Ÿå’Œæ„åœ–"
  
  modules:
    emotion_analyzer: true      # æƒ…æ„Ÿç†è§£
    intent_recognizer: true     # æ„åœ–è­˜åˆ¥  
    intimacy_calculator: true   # è¦ªå¯†åº¦æ„ŸçŸ¥
    context_analyzer: true      # å°è©±è„ˆçµ¡ç†è§£
  
  # æƒ…æ„Ÿå›æ‡‰å¢å¼·
  emotional_enhancement:
    sensitivity_level: "high"           # æƒ…æ„Ÿæ•æ„Ÿåº¦ï¼šhigh/medium/low
    empathy_factor: 1.8                # å…±æƒ…èƒ½åŠ›ä¿‚æ•¸
    emotional_memory_length: 8         # æƒ…æ„Ÿè¨˜æ†¶é•·åº¦
    intimacy_growth_rate: 0.1          # è¦ªå¯†åº¦å¢é•·é€Ÿåº¦
  
  # è‡ªç„¶èªè¨€æŒ‡å°
  natural_guidance:
    use_technical_terms: false         # é¿å…æŠ€è¡“è¡“èª
    prefer_emotional_language: true    # åå¥½æƒ…æ„ŸåŒ–èªè¨€
    personality_consistency: true      # ä¿æŒäººæ ¼ä¸€è‡´æ€§
    response_warmth_level: "high"      # å›æ‡‰æº«æš–åº¦

# API é…ç½®
api:
  host: "127.0.0.1"
  port: 8000
  workers: 1
  log_level: "info"
  cors_origins: ["*"]

# ğŸš€ æ€§èƒ½å„ªåŒ–é…ç½® - æ¨¡å‹åŠ é€Ÿè¨­ç½®
performance:
  # éœæ…‹KVç·©å­˜å„ªåŒ–
  enable_static_cache: true           # å•Ÿç”¨éœæ…‹KVç·©å­˜ï¼ˆæå‡15-25%é€Ÿåº¦ï¼‰
  max_cache_length: 2048              # æœ€å¤§ç·©å­˜é•·åº¦ï¼ˆå¤šGPUè‡ªå‹•èª¿æ•´åˆ°3072ï¼‰
  
  # Torch Compileå„ªåŒ–  
  enable_torch_compile: true          # å•Ÿç”¨Torchç·¨è­¯å„ªåŒ–ï¼ˆæå‡20-40%é€Ÿåº¦ï¼‰
  
  # å…¶ä»–å„ªåŒ–é¸é …
  enable_speed_optimization: true     # ç¸½é«”é€Ÿåº¦å„ªåŒ–é–‹é—œ
  use_4bit_quantization: false        # 4bité‡åŒ–ï¼ˆæš«ä¸ä½¿ç”¨ï¼Œä¿æŒ8bitï¼‰
  use_flash_attention: false          # Flash Attentionï¼ˆæš«ä¸ä½¿ç”¨ï¼‰

# ç³»çµ±å„ªåŒ– (Windows 11)
system:
  performance_optimization:
    enable_llm_cache: true
    cache_size: 500
    enable_rag_cache: true
    rag_cache_ttl: 3600
    enable_semantic_cache: true

  memory_optimization: true
  gpu_memory_fraction: 0.8
  cpu_threads: -1  # ä½¿ç”¨æ‰€æœ‰å¯ç”¨æ ¸å¿ƒ
  cache_dir: "./scrpitsV2/LLM/data/cache"
  log_dir: "./scrpitsV2/LLM/logs"

  # èªç¾©åˆ†æç³»çµ±å„ªåŒ–
  semantic_optimization:
    enable_caching: true               # å•Ÿç”¨èªç¾©åˆ†æçµæœç·©å­˜
    cache_size: 1000                   # ç·©å­˜å¤§å°
    analysis_timeout: 5.0              # åˆ†æè¶…æ™‚æ™‚é–“(ç§’)
    fallback_mode: "graceful"          # é™ç´šæ¨¡å¼ï¼šgraceful/disabled

# æ•´åˆåŠŸèƒ½ç‹€æ…‹
integration_status:
  core_semantic_analysis: true         # Core.py èªç¾©åˆ†ææ•´åˆ
  llm_manager_enhancement: true        # LLM Manager å¢å¼·
  rag_semantic_search: true            # RAG èªç¾©æœç´¢
  knowledge_base_integration: true     # çŸ¥è­˜åº«æ•´åˆ
  human_like_responses: true           # äººæ€§åŒ–å›æ‡‰
  
  # ğŸš€ æ–°å¢ï¼šæ€§èƒ½å„ªåŒ–ç‹€æ…‹
  performance_optimizations: true      # æ€§èƒ½å„ªåŒ–æ•´åˆ
  static_kv_cache: true                # éœæ…‹KVç·©å­˜
  torch_compile: true                  # Torchç·¨è­¯å„ªåŒ–
  model_acceleration: true             # æ¨¡å‹åŠ é€Ÿ
  
  # æ•´åˆç‰ˆæœ¬ä¿¡æ¯
  integration_version: "1.1.0"         # æ›´æ–°ç‰ˆæœ¬è™Ÿ
  last_updated: "2025-08-18"           # æ›´æ–°æ—¥æœŸ
  features_enabled: [
    "æ·±åº¦æƒ…æ„Ÿç†è§£",
    "èªç¾©å¢å¼·æª¢ç´¢", 
    "äººæ€§åŒ–æç¤ºè©ç”Ÿæˆ",
    "å‹•æ…‹åƒæ•¸èª¿æ•´",
    "è¦ªå¯†åº¦æ„ŸçŸ¥",
    "æ™ºèƒ½é¢¨æ ¼åŒ¹é…",
    "éœæ…‹KVç·©å­˜å„ªåŒ–",                  # æ–°å¢
    "Torchç·¨è­¯åŠ é€Ÿ",                   # æ–°å¢
    "çµ„åˆå„ªåŒ–ç­–ç•¥"                     # æ–°å¢
  ]