#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºæ…§æ›è¡Œè™•ç†å™¨
æ ¹æ“šèªç¾©è½‰æŠ˜ã€å•å€™ã€æƒ…æ„Ÿè¡¨é”ç­‰é‚è¼¯è‡ªå‹•ç‚ºå›æ‡‰æ·»åŠ æ›è¡Œï¼Œè®“å›è¦†æ›´åƒçœŸäºº
"""

import re
import logging
from typing import Dict, List, Tuple, Optional
from .base_filter import BaseResponseFilter

# ä½¿ç”¨çµ±ä¸€çš„æ—¥èªŒé…ç½®
try:
    from ..log_config import setup_module_logging
    logger = setup_module_logging(__name__, startup_mode=True)
except ImportError:
    logger = logging.getLogger(__name__)

class SmartLineBreakFilter(BaseResponseFilter):
    """æ™ºæ…§æ›è¡Œè™•ç†å™¨ - è®“å›æ‡‰æ›´è‡ªç„¶åœ°åˆ†æ®µ"""
    
    def __init__(self, chat_instance=None):
        super().__init__(chat_instance)
        
        # å•å€™èªæ¨¡å¼
        self.greeting_patterns = [
            r'(ä½ å¥½|å“ˆå›‰|å—¨|hi|hello|æ—©å®‰|åˆå®‰|æ™šå®‰|ãŠã¯ã‚ˆã†|ã“ã‚“ã«ã¡ã¯|ã“ã‚“ã°ã‚“ã¯)',
            r'(æ­¡è¿|å›ä¾†|è¾›è‹¦äº†|å›å®¶äº†)',
            r'(ä»Šå¤©|ç¾åœ¨|é€™æ™‚å€™|å‰›æ‰)'
        ]
        
        # æƒ…æ„Ÿè¡¨é”æ¨¡å¼
        self.emotion_patterns = [
            r'(çœŸçš„|ç¢ºå¯¦|ç•¶ç„¶|æ²’éŒ¯|æ˜¯å•Š|å°å‘¢)',
            r'(å¥½æ£’|å¤ªå¥½äº†|çœŸæ£’|å²å®³|è®š|ä¸éŒ¯)',
            r'(å¥½å¯æ„›|å¥½ç”œ|å¥½æº«æŸ”|å¥½æš–)',
            r'(æŠ±æ­‰|å°ä¸èµ·|ä¸å¥½æ„æ€|sorry)',
            r'(è¬è¬|æ„Ÿè¬|thank)',
            r'(å“ˆå“ˆ|å‘µå‘µ|å˜»å˜»|aha|å“ˆ|å‘µ)'
        ]
        
        # èªç¾©è½‰æŠ˜è©
        self.transition_patterns = [
            r'(ä¸é|ä½†æ˜¯|å¯æ˜¯|ç„¶è€Œ|åªæ˜¯|é›–ç„¶|å„˜ç®¡)',
            r'(æ‰€ä»¥|å› æ­¤|é‚£éº¼|é€™æ¨£|æ–¼æ˜¯|çµæœ)',
            r'(å¦å¤–|é‚„æœ‰|è€Œä¸”|å†èªª|é †ä¾¿|å°äº†)',
            r'(å…¶å¯¦|å¯¦éš›ä¸Š|èªªå¯¦è©±|è€å¯¦èªª|å¦ç™½èªª)',
            r'(ç¸½ä¹‹|ç¸½è€Œè¨€ä¹‹|ç°¡å–®èªª|åæ­£|anyway)'
        ]
        
        # å•å¥æ¨¡å¼
        self.question_patterns = [
            r'([ï¼Ÿ?])',
            r'(è¦ä¸è¦|è¦å—|å°å—|æ˜¯å—|å¥½å—|å¦‚ä½•|æ€éº¼æ¨£)',
            r'(ä»€éº¼|å“ªå€‹|å“ªè£¡|ç‚ºä»€éº¼|æ€éº¼|when|where|what|why|how)'
        ]
        
        # å»ºè­°æˆ–é‚€è«‹æ¨¡å¼
        self.suggestion_patterns = [
            r'(å»ºè­°|æ¨è–¦|å¯ä»¥|ä¸å¦‚|è¦ä¸|æˆ–è¨±)',
            r'(ä¸€èµ·|æˆ‘å€‘|ä¾†å§|èµ°å§|å»å§)',
            r'(è©¦è©¦|çœ‹çœ‹|è½è½|æƒ³æƒ³|è€ƒæ…®)'
        ]
        
        # è¦ªå¯†è¡¨é”æ¨¡å¼
        self.intimate_patterns = [
            r'(è¦ªæ„›çš„|å¯¶è²|darling|honey)',
            r'(æ„›ä½ |å–œæ­¡ä½ |miss you|æƒ³ä½ )',
            r'(æŠ±æŠ±|è¦ªè¦ª|æ‘¸æ‘¸|è¹­è¹­|â™ª|â™¡|ğŸ’•|â¤ï¸)'
        ]
        
        # æ™‚é–“ç›¸é—œæ¨¡å¼
        self.time_patterns = [
            r'(ç¾åœ¨|å‰›æ‰|ç­‰ç­‰|ä¹‹å¾Œ|ç¨å¾Œ|later)',
            r'(ä»Šå¤©|æ˜å¤©|æ˜¨å¤©|yesterday|today|tomorrow)',
            r'(æ—©ä¸Š|ä¸­åˆ|ä¸‹åˆ|æ™šä¸Š|æ·±å¤œ|morning|evening|night)'
        ]
        
        # ä¸æ‡‰è©²åœ¨å‰é¢æ›è¡Œçš„è©
        self.no_break_before = [
            r'(äº†|å‘¢|å•Š|å“¦|å–”|å“©|å˜›|å‘€|è€¶|å“‡)',
            r'(çš„|åœ°|å¾—)',
            r'(â™ª|â™¡|ï½|~)',
            r'([ã€‚ï¼ï¼Ÿï¼Œï¼›ã€.!?,:;])'
        ]
        
        # ç·¨è­¯æ­£å‰‡è¡¨é”å¼æ¨¡å¼
        self._compile_patterns()
        
        logger.debug("SmartLineBreakFilter æ™ºæ…§æ›è¡Œè™•ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _compile_patterns(self):
        """ç·¨è­¯æ­£å‰‡è¡¨é”å¼æ¨¡å¼ä»¥æé«˜æ•ˆèƒ½"""
        self.compiled_patterns = {
            'greeting': [re.compile(pattern, re.IGNORECASE) for pattern in self.greeting_patterns],
            'emotion': [re.compile(pattern, re.IGNORECASE) for pattern in self.emotion_patterns],
            'transition': [re.compile(pattern, re.IGNORECASE) for pattern in self.transition_patterns],
            'question': [re.compile(pattern, re.IGNORECASE) for pattern in self.question_patterns],
            'suggestion': [re.compile(pattern, re.IGNORECASE) for pattern in self.suggestion_patterns],
            'intimate': [re.compile(pattern, re.IGNORECASE) for pattern in self.intimate_patterns],
            'time': [re.compile(pattern, re.IGNORECASE) for pattern in self.time_patterns],
            'no_break_before': [re.compile(pattern, re.IGNORECASE) for pattern in self.no_break_before]
        }
    
    def _should_filter(self, response: str, user_input: str = "", context: Dict = None) -> bool:
        """æª¢æŸ¥æ˜¯å¦éœ€è¦é€²è¡Œæ›è¡Œè™•ç†"""
        if not response or len(response.strip()) < 10:  # å¤ªçŸ­çš„å›æ‡‰ä¸éœ€è¦æ›è¡Œ
            return False
        
        # å¦‚æœå·²ç¶“æœ‰é©ç•¶çš„æ›è¡Œï¼Œä¸”ä¸æ˜¯éé•·çš„å–®è¡Œï¼Œå¯èƒ½ä¸éœ€è¦è™•ç†
        lines = response.split('\n')
        if len(lines) > 1:
            # æª¢æŸ¥æ˜¯å¦æœ‰éé•·çš„è¡Œ
            has_long_lines = any(len(line.strip()) > 50 for line in lines)
            if not has_long_lines:
                return False
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å¤šå€‹å¥å­ï¼ˆå³ä½¿è¼ƒçŸ­ä¹Ÿæ‡‰è©²è™•ç†ï¼‰
        sentence_count = len([s for s in response.split('ï¼Ÿ') + response.split('ï¼') + response.split('ã€‚') + response.split('â™ª') + response.split('â™¡') if s.strip()])
        if sentence_count > 1:
            return True
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«å•å€™èªã€å•å¥ã€æƒ…æ„Ÿè¡¨é”ç­‰éœ€è¦æ›è¡Œçš„å…ƒç´ 
        has_special_elements = (
            any(pattern.search(response) for pattern in self.compiled_patterns['greeting']) or
            any(pattern.search(response) for pattern in self.compiled_patterns['question']) or
            any(pattern.search(response) for pattern in self.compiled_patterns['emotion']) or
            any(pattern.search(response) for pattern in self.compiled_patterns['intimate'])
        )
        
        return has_special_elements or len(response.strip()) >= 20
    
    def _apply_filter(self, response: str, user_input: str = "", context: Dict = None) -> str:
        """æ‡‰ç”¨æ™ºæ…§æ›è¡Œè™•ç†"""
        if not response:
            return response
        
        logger.debug(f"é–‹å§‹æ™ºæ…§æ›è¡Œè™•ç†: {response[:30]}...")
        
        # å…ˆç§»é™¤ç¾æœ‰çš„æ›è¡Œï¼Œé‡æ–°è™•ç†
        cleaned_response = ' '.join(response.split())
        
        # æ‰¾å‡ºæ‰€æœ‰å¯èƒ½çš„æ›è¡Œé»
        break_points = self._find_break_points(cleaned_response)
        
        # æ ¹æ“šæ›è¡Œé»é‡æ–°çµ„ç¹”æ–‡æœ¬
        formatted_response = self._apply_line_breaks(cleaned_response, break_points)
        
        logger.debug(f"æ›è¡Œè™•ç†å®Œæˆ: {len(break_points)} å€‹æ›è¡Œé»")
        return formatted_response
    
    def smart_sentence_split(self, response: str) -> List[str]:
        """
        æ™ºæ…§åˆ†å¥è™•ç† - å°‡å›æ‡‰åˆ†å‰²æˆè‡ªç„¶çš„å¥å­
        ä½¿ç”¨æ›´å®‰å…¨çš„é‚è¼¯é¿å…æ¨™é»éŒ¯ä½
        """
        if not response:
            return []
        
        # ç§»é™¤å¤šé¤˜çš„ç©ºç™½å’Œæ›è¡Œ
        response = ' '.join(response.split()).strip()
        
        # ä½¿ç”¨æ›´å®‰å…¨çš„åˆ†å¥æ–¹æ³•
        sentences = []
        current = ""
        
        i = 0
        while i < len(response):
            char = response[i]
            current += char
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºåˆ†å¥é»
            should_split = False
            next_start = i + 1
            
            # 1. å¼·åˆ¶åˆ†å¥æ¨™é»ï¼šã€‚ï¼ï¼Ÿ!?
            if char in ['ã€‚', 'ï¼', 'ï¼Ÿ', '!', '?']:
                # æ”¶é›†å¾ŒçºŒçš„è¡¨æƒ…ç¬¦è™Ÿå’Œèªæ°£è©
                while next_start < len(response) and response[next_start] in ['â™ª', 'â™¡', 'ï½', 'ğŸ’•', 'â¤ï¸', ' ', 'å‘¢', 'å•Š', 'å“¦', 'å‘€', 'å§']:
                    if response[next_start] != ' ':
                        current += response[next_start]
                    next_start += 1
                should_split = True
            
            # 2. çœç•¥è™Ÿè™•ç†
            elif char == '.' and i + 2 < len(response) and response[i+1:i+3] == '..':
                current += '..'
                next_start = i + 3
                if len(current.strip()) >= 6:
                    remaining = response[next_start:].strip()
                    if len(remaining) > 5:
                        should_split = True
            
            # 3. è¡¨æƒ…ç¬¦è™Ÿçµå°¾ï¼ˆæœ‰æ¢ä»¶åˆ†å¥ï¼‰
            elif char in ['â™ª', 'â™¡', 'ï½', 'ğŸ’•', 'â¤ï¸'] and len(current.strip()) >= 8:
                remaining = response[i+1:].strip()
                if len(remaining) > 10:
                    # æª¢æŸ¥æ˜¯å¦å¾Œé¢æœ‰è½‰æŠ˜è©
                    if any(remaining.startswith(word) for word in ['å—¯', 'ä¸é', 'ä½†æ˜¯', 'å¯æ˜¯', 'å¦å¤–', 'é‚„æœ‰', 'è€Œä¸”']):
                        should_split = True
            
            # 4. é€—è™Ÿè™•ç†ï¼ˆåªåœ¨æœ‰æ˜ç¢ºè½‰æŠ˜æ™‚åˆ†å¥ï¼‰
            elif char == 'ï¼Œ' and len(current.strip()) >= 15:
                remaining = response[i+1:].strip()
                if len(remaining) > 8:
                    # åªåœ¨æœ‰æ˜ç¢ºè½‰æŠ˜è©æ™‚æ‰åˆ†å¥
                    if any(remaining.startswith(word) for word in ['ä¸é', 'ä½†æ˜¯', 'å¯æ˜¯', 'ç„¶è€Œ', 'å¦å¤–', 'é‚„æœ‰']):
                        should_split = True
            
            # 5. å–®ç¨çš„è‹±æ–‡å¥è™Ÿ
            elif char == '.' and len(current.strip()) >= 8:
                remaining = response[i+1:].strip()
                if len(remaining) > 5 and not remaining.startswith('.'):
                    should_split = True
            
            # åŸ·è¡Œåˆ†å¥
            if should_split:
                cleaned = current.strip()
                if len(cleaned) >= 3:
                    sentences.append(cleaned)
                current = ""
                i = next_start - 1
            
            i += 1
        
        # è™•ç†å‰©é¤˜å…§å®¹
        if current.strip():
            sentences.append(current.strip())
        
        # å¾Œè™•ç†ï¼šä¿®æ­£æ¨™é»å’Œåˆä½µ
        return self._final_process_sentences(sentences)
    
    def _find_best_cut_position(self, text: str) -> int:
        """å°‹æ‰¾æœ€ä½³çš„åˆ‡åˆ†ä½ç½®"""
        # åˆ‡åˆ†å„ªå…ˆç´šï¼šæ¨™é» > èªç¾©è© > åŠ©è© > ç©ºæ ¼
        cut_priorities = [
            (['ï¼Œ', 'ã€', ';', ','], 70, 90),  # æ¨™é»ç¬¦è™Ÿï¼Œåœ¨70-90%ä½ç½®
            (['çš„', 'äº†', 'é', 'è‘—', 'å‘¢', 'å•Š', 'å“¦'], 60, 85),  # åŠ©è©
            (['ä¸€èµ·', 'å¯ä»¥', 'æ‡‰è©²', 'å¯èƒ½', 'æˆ–è€…', 'è¦ä¸'], 50, 80),  # èªç¾©è©
            ([' '], 50, 85),  # ç©ºæ ¼
        ]
        
        text_len = len(text)
        best_pos = -1
        best_score = 0
        
        for markers, min_pct, max_pct in cut_priorities:
            min_pos = int(text_len * min_pct / 100)
            max_pos = int(text_len * max_pct / 100)
            
            for marker in markers:
                # å¾ç†æƒ³ä½ç½®å‘å…©é‚Šæœç´¢
                ideal_pos = int(text_len * 0.75)  # ç†æƒ³ä½ç½®75%
                
                # å‘å‰æœç´¢
                for pos in range(ideal_pos, min_pos - 1, -1):
                    if pos + len(marker) <= text_len and text[pos:pos + len(marker)] == marker:
                        score = 100 - abs(pos - ideal_pos)  # è¶Šæ¥è¿‘ç†æƒ³ä½ç½®åˆ†æ•¸è¶Šé«˜
                        if score > best_score:
                            best_score = score
                            best_pos = pos + len(marker)
                
                # å‘å¾Œæœç´¢
                for pos in range(ideal_pos + 1, min(max_pos, text_len - len(marker) + 1)):
                    if text[pos:pos + len(marker)] == marker:
                        score = 100 - abs(pos - ideal_pos)
                        if score > best_score:
                            best_score = score
                            best_pos = pos + len(marker)
        
        return best_pos if best_pos > 0 else text_len // 2
    
    def _final_process_sentences(self, sentences: List[str]) -> List[str]:
        """
        æœ€çµ‚è™•ç†å¥å­ - ä¿®æ­£æ¨™é»éŒ¯èª¤ä¸¦æ™ºæ…§åˆä½µ
        """
        if not sentences:
            return sentences
        
        # ä¿®æ­£æ¯å€‹å¥å­çš„æ¨™é»å•é¡Œ
        corrected = []
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
            
            # å°ˆé–€ä¿®æ­£æ¨™é»éŒ¯èª¤
            sentence = self._fix_punctuation_errors(sentence)
            
            # æª¢æŸ¥å¥å­æ˜¯å¦åˆç†
            if len(sentence) >= 2:
                corrected.append(sentence)
        
        # æ™ºæ…§åˆä½µç›¸é—œå¥å­
        final = []
        i = 0
        
        while i < len(corrected):
            current = corrected[i]
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦èˆ‡ä¸‹ä¸€å¥åˆä½µ
            if i + 1 < len(corrected):
                next_sent = corrected[i + 1]
                
                # åˆä½µæ¢ä»¶
                merge = False
                total_len = len(current + next_sent)
                
                # 1. å…©å¥éƒ½è¼ƒçŸ­ä¸”ç¸½é•·åº¦åˆç†
                if len(current) < 12 and len(next_sent) < 15 and total_len < 40:
                    merge = True
                
                # 2. ç•¶å‰å¥ä»¥ä¸å®Œæ•´è©çµå°¾
                elif any(current.rstrip('â™ªâ™¡ï½ï¼ï¼Ÿã€‚').endswith(w) for w in ['æ˜¯', 'æœƒ', 'è¦', 'æƒ³', 'å¯ä»¥', 'æ‡‰è©²', 'ä¸€èµ·', 'èƒ½']):
                    if total_len < 50:
                        merge = True
                
                # 3. èªç¾©é€£è²«
                elif self._check_semantic_connection(current, next_sent) and total_len < 55:
                    merge = True
                
                if merge:
                    merged = current.rstrip() + ' ' + next_sent.lstrip()
                    final.append(merged)
                    i += 2
                    continue
            
            final.append(current)
            i += 1
        
        return final
    
    def _check_semantic_connection(self, sent1: str, sent2: str) -> bool:
        """æª¢æŸ¥å…©å¥æ˜¯å¦æœ‰èªç¾©é€£æ¥"""
        # æª¢æŸ¥å…±åŒä¸»é¡Œè©
        theme_words = ['ä½ ', 'æˆ‘', 'éœ²é†¬', 'ä»Šå¤©', 'ä¸€èµ·', 'å»', 'åš', 'ç©', 'å¥½', 'æƒ³']
        
        sent1_themes = [w for w in theme_words if w in sent1]
        sent2_themes = [w for w in theme_words if w in sent2]
        
        # æœ‰å…±åŒä¸»é¡Œä¸”å¥å­éƒ½ä¸å¤ªé•·
        return len(set(sent1_themes) & set(sent2_themes)) > 0 and len(sent1) < 20 and len(sent2) < 20
    
    def _fix_punctuation_errors(self, sentence: str) -> str:
        """å°ˆé–€ä¿®æ­£æ¨™é»ç¬¦è™ŸéŒ¯èª¤"""
        # ç§»é™¤æ˜é¡¯çš„éŒ¯èª¤æ¨™é»çµ„åˆ
        sentence = re.sub(r'å•¦\s*ï¼Œ\s*ï¼Ÿ', 'å•¦ï½', sentence)
        sentence = re.sub(r'å‘¢\s*ï¼Œ\s*ï¼Ÿ', 'å‘¢ï¼Ÿ', sentence) 
        sentence = re.sub(r'å“¦\s*ï¼Œ\s*ï¼Ÿ', 'å“¦ï½', sentence)
        sentence = re.sub(r'å•Š\s*ï¼Œ\s*ï¼Ÿ', 'å•Šï½', sentence)
        
        # ä¿®æ­£å­¤ç«‹çš„å•è™Ÿ
        sentence = re.sub(r'ï¼Œ\s*ï¼Ÿ\s*$', 'ï½', sentence)  # å¥å°¾çš„ "ï¼Œï¼Ÿ" -> "ï½"
        sentence = re.sub(r'ï¼Œ\s*ï¼Ÿ', 'ï¼Ÿ', sentence)  # å…¶ä»–çš„ "ï¼Œï¼Ÿ" -> "ï¼Ÿ"
        
        # ä¿®æ­£å…¶ä»–éŒ¯èª¤çµ„åˆ
        sentence = re.sub(r'ï¼Œ\s*ï¼', 'ï¼', sentence)
        sentence = re.sub(r'ã€‚\s*ï¼Ÿ', 'ï¼Ÿ', sentence)
        sentence = re.sub(r'ã€‚\s*ï¼', 'ï¼', sentence)
        
        return sentence
    
    def _fix_sentence_issues(self, sentence: str) -> str:
        """ä¿®æ­£å¥å­ä¸­çš„å¸¸è¦‹å•é¡Œ"""
        # ä¿®æ­£é‡è¤‡çš„æ¨™é»ç¬¦è™Ÿ
        sentence = re.sub(r'([â™ªâ™¡ï½])\1+', r'\1', sentence)
        
        # ä¿®æ­£ç©ºæ ¼å•é¡Œ
        sentence = re.sub(r'\s+', ' ', sentence).strip()
        
        # ä¿®æ­£ä¸­è‹±æ–‡ä¹‹é–“çš„ç©ºæ ¼
        sentence = re.sub(r'([a-zA-Z])\s+([^\sa-zA-Z])', r'\1\2', sentence)
        sentence = re.sub(r'([^\sa-zA-Z])\s+([a-zA-Z])', r'\1\2', sentence)
        
        # ä¿®æ­£éŒ¯ä½çš„æ¨™é»ç¬¦è™Ÿï¼ˆé‡é»ä¿®æ­£ï¼‰
        sentence = re.sub(r'å•¦\s*ï¼Œ\s*ï¼Ÿ', 'å•¦ï½', sentence)  # ä¿®æ­£ "å•¦ï¼Œï¼Ÿ" -> "å•¦ï½"
        sentence = re.sub(r'å‘¢\s*ï¼Œ\s*ï¼Ÿ', 'å‘¢ï¼Ÿ', sentence)  # ä¿®æ­£ "å‘¢ï¼Œï¼Ÿ" -> "å‘¢ï¼Ÿ"
        sentence = re.sub(r'å“¦\s*ï¼Œ\s*ï¼Ÿ', 'å“¦ï½', sentence)  # ä¿®æ­£ "å“¦ï¼Œï¼Ÿ" -> "å“¦ï½"
        sentence = re.sub(r'å•Š\s*ï¼Œ\s*ï¼Ÿ', 'å•Šï½', sentence)  # ä¿®æ­£ "å•Šï¼Œï¼Ÿ" -> "å•Šï½"
        sentence = re.sub(r'ï¼Œ\s*ï¼Ÿ\s*$', 'ï½', sentence)  # å¥å°¾çš„ "ï¼Œï¼Ÿ" -> "ï½"
        sentence = re.sub(r'ï¼Œ\s*ï¼Ÿ', 'ï¼Ÿ', sentence)  # å…¶ä»–çš„ "ï¼Œï¼Ÿ" -> "ï¼Ÿ"
        sentence = re.sub(r'ï¼Œ\s*ï¼', 'ï¼', sentence)  # ä¿®æ­£ "ï¼Œï¼" -> "ï¼"
        sentence = re.sub(r'ã€‚\s*ï¼Ÿ', 'ï¼Ÿ', sentence)  # ä¿®æ­£ "ã€‚ï¼Ÿ" -> "ï¼Ÿ"
        
        # ä¿®æ­£å¥å­ä¸­çš„é€£çºŒæ¨™é»
        sentence = re.sub(r'[ã€‚ï¼Œ]\s*([ï¼Ÿï¼])', r'\1', sentence)
        
        # ä¿®æ­£é€£çºŒé»è™Ÿ
        sentence = re.sub(r'\.{2,}', '...', sentence)  # è¦ç¯„åŒ–çœç•¥è™Ÿ
        sentence = re.sub(r'\.{1}([^.])', r'.\1', sentence)  # ç¢ºä¿å–®é»å¾Œæœ‰å…§å®¹
        
        # ç‰¹æ®Šä¿®æ­£ï¼šç§»é™¤ä¸æ‡‰è©²å­˜åœ¨çš„å­¤ç«‹å•è™Ÿ
        sentence = re.sub(r'^[ï¼Œã€‚]\s*ï¼Ÿ', 'ï¼Ÿ', sentence)  # å¥é¦–çš„éŒ¯ä½æ¨™é»
        sentence = re.sub(r'ï¼Œï¼Ÿ$', 'ï¼Ÿ', sentence)  # å¥å°¾çš„éŒ¯ä½æ¨™é»
        
        # ç¢ºä¿å¥å­æœ‰é©ç•¶çš„çµå°¾
        if sentence and not re.search(r'[ã€‚ï¼ï¼Ÿâ™ªâ™¡ï½.!?]$', sentence):
            # æ ¹æ“šå…§å®¹æ·»åŠ é©ç•¶çš„çµå°¾
            if any(word in sentence for word in ['å—', 'å‘¢', 'å§', '?','~']):
                if not sentence.endswith('?'):
                    sentence += 'ï¼Ÿ'
            elif any(word in sentence for word in ['ï¼', '!', 'å¤ª', 'çœŸ', 'å¥½', 'æ£’']):
                if not sentence.endswith('!') and 'ï¼' not in sentence:
                    sentence += 'ï¼'
            else:
                sentence += 'â™ª'
        
        return sentence
    
    def _find_break_points(self, text: str) -> List[Tuple[int, str, float]]:
        """
        æ‰¾å‡ºæ‰€æœ‰å¯èƒ½çš„æ›è¡Œé»
        
        Returns:
            List[Tuple[int, str, float]]: (ä½ç½®, é¡å‹, æ¬Šé‡)
        """
        break_points = []
        
        # 1. å•å€™èªå¾Œæ›è¡Œ
        for pattern in self.compiled_patterns['greeting']:
            for match in pattern.finditer(text):
                # ç¢ºä¿å•å€™èªå¾Œé¢æœ‰å…§å®¹
                after_pos = match.end()
                if after_pos < len(text) - 3:
                    break_points.append((after_pos, 'greeting', 0.9))
        
        # 2. æƒ…æ„Ÿè¡¨é”å¾Œæ›è¡Œ
        for pattern in self.compiled_patterns['emotion']:
            for match in pattern.finditer(text):
                after_pos = match.end()
                # æª¢æŸ¥å¾Œé¢æ˜¯å¦æœ‰è¶³å¤ å…§å®¹
                if after_pos < len(text) - 5:
                    # å¦‚æœæƒ…æ„Ÿè¡¨é”å¾Œæœ‰é€—è™Ÿæˆ–å¥è™Ÿï¼Œåœ¨å…¶å¾Œæ›è¡Œ
                    next_char_pos = self._find_next_punctuation(text, after_pos)
                    if next_char_pos and next_char_pos < len(text) - 3:
                        break_points.append((next_char_pos, 'emotion', 0.8))
                    else:
                        break_points.append((after_pos, 'emotion', 0.7))
        
        # 3. èªç¾©è½‰æŠ˜å‰æ›è¡Œ
        for pattern in self.compiled_patterns['transition']:
            for match in pattern.finditer(text):
                before_pos = match.start()
                # ç¢ºä¿è½‰æŠ˜è©å‰é¢æœ‰å…§å®¹
                if before_pos > 3:
                    break_points.append((before_pos, 'transition', 0.85))
        
        # 4. å•å¥å¾Œæ›è¡Œ
        for pattern in self.compiled_patterns['question']:
            for match in pattern.finditer(text):
                after_pos = match.end()
                if after_pos < len(text) - 3:
                    break_points.append((after_pos, 'question', 0.8))
        
        # 5. å»ºè­°æˆ–é‚€è«‹å‰æ›è¡Œ
        for pattern in self.compiled_patterns['suggestion']:
            for match in pattern.finditer(text):
                before_pos = match.start()
                if before_pos > 5:
                    break_points.append((before_pos, 'suggestion', 0.75))
        
        # 6. è¦ªå¯†è¡¨é”ç¨ç«‹æˆè¡Œ
        for pattern in self.compiled_patterns['intimate']:
            for match in pattern.finditer(text):
                before_pos = match.start()
                after_pos = match.end()
                
                # è¦ªå¯†è¡¨é”å‰æ›è¡Œ
                if before_pos > 3:
                    break_points.append((before_pos, 'intimate_before', 0.9))
                
                # è¦ªå¯†è¡¨é”å¾Œæ›è¡Œï¼ˆå¦‚æœå¾Œé¢é‚„æœ‰å…§å®¹ï¼‰
                if after_pos < len(text) - 3:
                    break_points.append((after_pos, 'intimate_after', 0.9))
        
        # 7. æ™‚é–“è¡¨é”å¾Œæ›è¡Œ
        for pattern in self.compiled_patterns['time']:
            for match in pattern.finditer(text):
                after_pos = match.end()
                # æ‰¾åˆ°æ™‚é–“è¡¨é”å¾Œçš„é©ç•¶ä½ç½®
                next_punct_pos = self._find_next_punctuation(text, after_pos)
                if next_punct_pos and next_punct_pos < len(text) - 3:
                    break_points.append((next_punct_pos, 'time', 0.7))
        
        # 8. é•·å¥å­çš„ä¸­é–“é»ï¼ˆåŸºæ–¼å¥å­é•·åº¦ï¼‰
        if len(text) > 60:
            break_points.extend(self._find_length_based_breaks(text))
        
        # éæ¿¾æ‰ä¸åˆé©çš„æ›è¡Œé»
        break_points = self._filter_break_points(text, break_points)
        
        # æŒ‰ä½ç½®æ’åºä¸¦å»é‡
        break_points = sorted(list(set(break_points)), key=lambda x: x[0])
        
        return break_points
    
    def _find_next_punctuation(self, text: str, start_pos: int) -> Optional[int]:
        """æ‰¾åˆ°ä¸‹ä¸€å€‹æ¨™é»ç¬¦è™Ÿçš„ä½ç½®"""
        # æ”¯æ´ä¸­è‹±æ–‡æ¨™é»ç¬¦è™Ÿ
        punct_pattern = re.compile(r'[ã€‚ï¼ï¼Ÿï¼Œï¼›ã€.!?,:;]')
        match = punct_pattern.search(text, start_pos)
        return match.end() if match else None
    
    def _find_length_based_breaks(self, text: str) -> List[Tuple[int, str, float]]:
        """åŸºæ–¼é•·åº¦æ‰¾åˆ°é©ç•¶çš„æ–·è¡Œé»"""
        breaks = []
        words = text.split()
        current_length = 0
        current_pos = 0
        
        for word in words:
            word_length = len(word)
            
            # å¦‚æœåŠ ä¸Šé€™å€‹è©æœƒè¶…éç†æƒ³é•·åº¦ï¼Œè€ƒæ…®åœ¨æ­¤è™•æ–·è¡Œ
            if current_length + word_length > 40 and current_length > 20:
                breaks.append((current_pos, 'length', 0.5))
                current_length = word_length
            else:
                current_length += word_length + 1  # +1 for space
            
            current_pos += word_length + 1
        
        return breaks
    
    def _filter_break_points(self, text: str, break_points: List[Tuple[int, str, float]]) -> List[Tuple[int, str, float]]:
        """éæ¿¾æ‰ä¸åˆé©çš„æ›è¡Œé»"""
        filtered_points = []
        
        for pos, break_type, weight in break_points:
            # æª¢æŸ¥æ˜¯å¦åœ¨ä¸æ‡‰è©²æ›è¡Œçš„è©å‰é¢
            should_skip = False
            
            for pattern in self.compiled_patterns['no_break_before']:
                # æª¢æŸ¥æ›è¡Œé»å¾Œé¢æ˜¯å¦ç·Šæ¥è‘—ä¸æ‡‰è©²æ›è¡Œçš„è©
                if pos < len(text):
                    substring = text[pos:pos+3]
                    if pattern.search(substring):
                        should_skip = True
                        break
            
            if not should_skip:
                # ç¢ºä¿æ›è¡Œé»å‰å¾Œéƒ½æœ‰è¶³å¤ çš„å…§å®¹
                if pos > 3 and pos < len(text) - 3:
                    filtered_points.append((pos, break_type, weight))
        
        return filtered_points
    
    def _apply_line_breaks(self, text: str, break_points: List[Tuple[int, str, float]]) -> str:
        """æ ¹æ“šæ›è¡Œé»æ‡‰ç”¨æ›è¡Œ"""
        if not break_points:
            return text
        
        # æ ¹æ“šæ¬Šé‡å’Œè·é›¢é¸æ“‡æœ€ä½³æ›è¡Œé»
        selected_breaks = self._select_optimal_breaks(text, break_points)
        
        # æ‡‰ç”¨æ›è¡Œ
        result_parts = []
        last_pos = 0
        
        for pos, _, _ in selected_breaks:
            if pos > last_pos:
                part = text[last_pos:pos].strip()
                if part:
                    result_parts.append(part)
                last_pos = pos
        
        # æ·»åŠ æœ€å¾Œä¸€éƒ¨åˆ†
        if last_pos < len(text):
            final_part = text[last_pos:].strip()
            if final_part:
                result_parts.append(final_part)
        
        return '\n'.join(result_parts)
    
    def _select_optimal_breaks(self, text: str, break_points: List[Tuple[int, str, float]]) -> List[Tuple[int, str, float]]:
        """é¸æ“‡æœ€ä½³çš„æ›è¡Œé»çµ„åˆ"""
        if not break_points:
            return []
        
        # æ ¹æ“šæ¬Šé‡æ’åº
        sorted_breaks = sorted(break_points, key=lambda x: x[2], reverse=True)
        
        selected = []
        min_distance = 15  # å…©å€‹æ›è¡Œé»ä¹‹é–“çš„æœ€å°è·é›¢
        
        for break_point in sorted_breaks:
            pos, break_type, weight = break_point
            
            # æª¢æŸ¥æ˜¯å¦èˆ‡å·²é¸æ“‡çš„æ›è¡Œé»å¤ªè¿‘
            too_close = any(abs(pos - selected_pos) < min_distance 
                          for selected_pos, _, _ in selected)
            
            if not too_close:
                selected.append(break_point)
        
        # æŒ‰ä½ç½®é‡æ–°æ’åº
        return sorted(selected, key=lambda x: x[0])
    
    def filter(self, response: str, user_input: str = "", context: Dict = None) -> str:
        """
        éæ¿¾å™¨ä¸»è¦æ–¹æ³• - å¯¦ä½œ BaseResponseFilter çš„æŠ½è±¡æ–¹æ³•
        æä¾›æ™ºæ…§æ›è¡Œå’Œåˆ†å¥åŠŸèƒ½
        
        Args:
            response: åŸå§‹å›æ‡‰
            user_input: ç”¨æˆ¶è¼¸å…¥
            context: å°è©±ä¸Šä¸‹æ–‡
            
        Returns:
            str: è™•ç†å¾Œçš„å›æ‡‰
        """
        try:
            self.stats['processed_count'] += 1
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦è™•ç†
            if not self._should_filter(response, user_input, context):
                return response
            
            # å„ªå…ˆä½¿ç”¨æ™ºæ…§åˆ†å¥ï¼Œç„¶å¾Œé‡æ–°çµ„åˆç‚ºå¤šè¡Œæ–‡æœ¬
            sentences = self.smart_sentence_split(response)
            
            if len(sentences) > 1:
                # å¤šå¥å­çš„æƒ…æ³ï¼Œæ ¹æ“šå…§å®¹æ±ºå®šæ›è¡Œç­–ç•¥
                filtered_response = self._optimize_multi_sentence_layout(sentences)
            else:
                # å–®å¥å­çš„æƒ…æ³ï¼Œä½¿ç”¨åŸæœ‰çš„æ›è¡Œé‚è¼¯
                filtered_response = self._apply_filter(response, user_input, context)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰ä¿®æ”¹
            if filtered_response != response:
                self.stats['modified_count'] += 1
                logger.debug(f"æ™ºæ…§æ›è¡Œè™•ç†å®Œæˆ: åŸå§‹ {len(response)} å­— -> è™•ç†å¾Œ {len(filtered_response)} å­—")
            
            return filtered_response
            
        except Exception as e:
            self.stats['error_count'] += 1
            logger.error(f"æ™ºæ…§æ›è¡Œè™•ç†ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            # ç™¼ç”ŸéŒ¯èª¤æ™‚è¿”å›åŸå§‹å›æ‡‰
            return response
    
    def _optimize_multi_sentence_layout(self, sentences: List[str]) -> str:
        """
        å„ªåŒ–å¤šå¥å­çš„å¸ƒå±€ï¼Œæ±ºå®šå“ªäº›å¥å­æ‡‰è©²åœ¨åŒä¸€è¡Œ
        """
        if not sentences:
            return ""
        
        if len(sentences) == 1:
            return sentences[0]
        
        # å°æ–¼2-3å¥çš„æƒ…æ³ï¼Œå„ªå…ˆè€ƒæ…®åˆ†è¡Œä»¥æé«˜å¯è®€æ€§
        if len(sentences) <= 3:
            # æª¢æŸ¥æ˜¯å¦æœ‰å•å¥ - å•å¥æ‡‰è©²ç¨ç«‹æˆè¡Œ
            questions = [s for s in sentences if self._is_question(s)]
            if questions:
                # æœ‰å•å¥ï¼Œå…¨éƒ¨åˆ†è¡Œ
                return '\n'.join(sentences)
            
            # æª¢æŸ¥å¥å­é•·åº¦
            total_length = sum(len(s) for s in sentences)
            if total_length > 40:  # ç¸½é•·åº¦è¶…é40å­—ç¬¦ï¼Œåˆ†è¡Œé¡¯ç¤º
                return '\n'.join(sentences)
        
        # åˆ†çµ„ç­–ç•¥ï¼š
        groups = []
        current_group = []
        current_length = 0
        
        for sentence in sentences:
            sentence_len = len(sentence)
            
            # æª¢æŸ¥æ˜¯å¦æ‡‰è©²ç¨ç«‹æˆè¡Œ
            should_separate = (
                self._is_emotional_expression(sentence) or
                self._is_question(sentence) or
                self._is_greeting(sentence) or
                sentence_len > 40
            )
            
            # æª¢æŸ¥æ˜¯å¦å¯ä»¥åˆä½µåˆ°ç•¶å‰çµ„
            can_merge = (
                not should_separate and
                current_length + sentence_len + 1 <= 50 and
                len(current_group) < 2 and
                len(sentences) > 3  # åªæœ‰å¥å­è¼ƒå¤šæ™‚æ‰åˆä½µ
            )
            
            if can_merge and current_group:
                current_group.append(sentence)
                current_length += sentence_len + 1
            else:
                # é–‹å§‹æ–°çµ„
                if current_group:
                    groups.append(' '.join(current_group))
                current_group = [sentence]
                current_length = sentence_len
        
        # æ·»åŠ æœ€å¾Œä¸€çµ„
        if current_group:
            groups.append(' '.join(current_group))
        
        return '\n'.join(groups)
    
    def _is_emotional_expression(self, sentence: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºæƒ…æ„Ÿè¡¨é”"""
        emotional_indicators = [
            'â™¡', 'â™ª', 'ï½', 'ğŸ’•', 'â¤ï¸',
            'å¥½é–‹å¿ƒ', 'å¥½å¿«æ¨‚', 'å¥½æ„›', 'å¥½æº«æš–', 'å¥½ç”œ',
            'è¶…ç´š', 'çœŸçš„', 'å¥½æ£’', 'å¤ªå¥½äº†', 'å²å®³'
        ]
        return any(indicator in sentence for indicator in emotional_indicators)
    
    def _is_question(self, sentence: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºå•å¥"""
        return ('ï¼Ÿ' in sentence or '?' in sentence or 
                any(word in sentence for word in ['å—', 'å‘¢', 'å§', 'è¦ä¸è¦', 'å¥½å—', 'å°å—']))
    
    def _is_greeting(self, sentence: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºå•å€™èª"""
        greetings = [
            'æ—©å®‰', 'åˆå®‰', 'æ™šå®‰', 'ä½ å¥½', 'å“ˆå›‰', 'å—¨',
            'æ­¡è¿', 'å›ä¾†', 'è¾›è‹¦äº†', 'hello', 'hi'
        ]
        return any(greeting in sentence.lower() for greeting in greetings)
    
    def get_filter_name(self) -> str:
        """å›å‚³éæ¿¾å™¨åç¨±"""
        return "SmartLineBreak"
    
    def get_filter_description(self) -> str:
        """å›å‚³éæ¿¾å™¨æè¿°"""
        return "æ™ºæ…§æ›è¡Œè™•ç†ï¼šæ ¹æ“šèªç¾©è½‰æŠ˜ã€å•å€™ã€æƒ…æ„Ÿè¡¨é”ç­‰é‚è¼¯è‡ªå‹•æ›è¡Œ"
    
    def _get_debug_info(self, original: str, filtered: str) -> Dict:
        """å–å¾—èª¿è©¦è³‡è¨Š"""
        original_lines = len(original.split('\n'))
        filtered_lines = len(filtered.split('\n'))
        
        return {
            'original_lines': original_lines,
            'new_lines': filtered_lines,
            'lines_added': filtered_lines - original_lines,
            'avg_line_length': sum(len(line) for line in filtered.split('\n')) / filtered_lines if filtered_lines > 0 else 0
        }
