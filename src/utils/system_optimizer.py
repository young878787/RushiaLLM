"""
Windows 11 ç³»çµ±å„ªåŒ–æ¨¡çµ„
"""

import logging
import os
import sys
import psutil
import torch
from pathlib import Path


class WindowsOptimizer:
    def __init__(self, config: dict):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.system_config = config.get('system', {})
    
    def optimize(self):
        """åŸ·è¡Œç³»çµ±å„ªåŒ–"""
        if sys.platform != "win32":
            self.logger.info("é Windows ç³»çµ±ï¼Œè·³é Windows å„ªåŒ–")
            return
        
        self.logger.info("ğŸ”§ é–‹å§‹ Windows 11 ç³»çµ±å„ªåŒ–...")
        
        try:
            self._set_process_priority()
            self._optimize_memory()
            self._setup_gpu_optimization()
            self._setup_cache_directories()
            self._log_system_info()
            
            self.logger.info("âœ… Windows 11 ç³»çµ±å„ªåŒ–å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ ç³»çµ±å„ªåŒ–å¤±æ•—: {e}")
    
    def _set_process_priority(self):
        """è¨­ç½®é€²ç¨‹å„ªå…ˆç´š"""
        try:
            import psutil
            current_process = psutil.Process()
            
            # è¨­ç½®ç‚ºé«˜å„ªå…ˆç´šï¼ˆä½†ä¸æ˜¯å¯¦æ™‚å„ªå…ˆç´šï¼Œé¿å…ç³»çµ±å¡æ­»ï¼‰
            if hasattr(psutil, 'HIGH_PRIORITY_CLASS'):
                current_process.nice(psutil.HIGH_PRIORITY_CLASS)
                self.logger.info("é€²ç¨‹å„ªå…ˆç´šå·²è¨­ç½®ç‚ºé«˜å„ªå…ˆç´š")
            
        except Exception as e:
            self.logger.warning(f"è¨­ç½®é€²ç¨‹å„ªå…ˆç´šå¤±æ•—: {e}")
    
    def _optimize_memory(self):
        """å…§å­˜å„ªåŒ–"""
        try:
            if self.system_config.get('memory_optimization', True):
                # è¨­ç½®ç’°å¢ƒè®Šé‡å„ªåŒ–å…§å­˜ä½¿ç”¨
                os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
                os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # é¿å…å¤šé€²ç¨‹è¡çª
                
                # ç²å–ç³»çµ±å…§å­˜ä¿¡æ¯
                memory = psutil.virtual_memory()
                self.logger.info(f"ç³»çµ±å…§å­˜: {memory.total // (1024**3)}GB, å¯ç”¨: {memory.available // (1024**3)}GB")
                
                # å¦‚æœå…§å­˜ä¸è¶³ï¼Œå»ºè­°å„ªåŒ–
                if memory.available < 8 * (1024**3):  # å°æ–¼8GBå¯ç”¨å…§å­˜
                    self.logger.warning("å¯ç”¨å…§å­˜è¼ƒå°‘ï¼Œå»ºè­°é—œé–‰å…¶ä»–æ‡‰ç”¨ç¨‹åº")
                
        except Exception as e:
            self.logger.warning(f"å…§å­˜å„ªåŒ–å¤±æ•—: {e}")
    
    def _setup_gpu_optimization(self):
        """GPU å„ªåŒ–è¨­ç½®"""
        try:
            if torch.cuda.is_available():
                gpu_count = torch.cuda.device_count()
                self.logger.info(f"æª¢æ¸¬åˆ° {gpu_count} å€‹ CUDA è¨­å‚™")
                
                for i in range(gpu_count):
                    gpu_name = torch.cuda.get_device_name(i)
                    gpu_memory = torch.cuda.get_device_properties(i).total_memory
                    self.logger.info(f"GPU {i}: {gpu_name}, å…§å­˜: {gpu_memory // (1024**3)}GB")
                
                # è¨­ç½® GPU å…§å­˜åˆ†é…ç­–ç•¥
                gpu_memory_fraction = self.system_config.get('gpu_memory_fraction', 0.8)
                if gpu_memory_fraction < 1.0:
                    torch.cuda.set_per_process_memory_fraction(gpu_memory_fraction)
                    self.logger.info(f"GPU å…§å­˜ä½¿ç”¨é™åˆ¶è¨­ç½®ç‚º {gpu_memory_fraction*100}%")
                
                # å•Ÿç”¨ CUDA å„ªåŒ–
                torch.backends.cudnn.benchmark = True
                torch.backends.cudnn.deterministic = False
                
            else:
                self.logger.warning("æœªæª¢æ¸¬åˆ° CUDA è¨­å‚™ï¼Œå°‡ä½¿ç”¨ CPU")
                
                # CPU å„ªåŒ–
                cpu_threads = self.system_config.get('cpu_threads', -1)
                if cpu_threads == -1:
                    cpu_threads = psutil.cpu_count()
                
                torch.set_num_threads(cpu_threads)
                self.logger.info(f"CPU ç·šç¨‹æ•¸è¨­ç½®ç‚º: {cpu_threads}")
                
        except Exception as e:
            self.logger.warning(f"GPU å„ªåŒ–è¨­ç½®å¤±æ•—: {e}")
    
    def _setup_cache_directories(self):
        """è¨­ç½®ç·©å­˜ç›®éŒ„"""
        try:
            cache_dir = Path(self.system_config.get('cache_dir', './cache'))
            cache_dir.mkdir(parents=True, exist_ok=True)
            
            # è¨­ç½® Transformers ç·©å­˜ç›®éŒ„
            os.environ['TRANSFORMERS_CACHE'] = str(cache_dir / 'transformers')
            os.environ['HF_HOME'] = str(cache_dir / 'huggingface')
            
            # è¨­ç½® Torch ç·©å­˜ç›®éŒ„
            os.environ['TORCH_HOME'] = str(cache_dir / 'torch')
            
            self.logger.info(f"ç·©å­˜ç›®éŒ„è¨­ç½®ç‚º: {cache_dir}")
            
        except Exception as e:
            self.logger.warning(f"è¨­ç½®ç·©å­˜ç›®éŒ„å¤±æ•—: {e}")
    
    def _log_system_info(self):
        """è¨˜éŒ„ç³»çµ±ä¿¡æ¯"""
        try:
            # CPU ä¿¡æ¯
            cpu_info = {
                'processor': psutil.cpu_count(logical=False),
                'logical_cores': psutil.cpu_count(logical=True),
                'frequency': psutil.cpu_freq().current if psutil.cpu_freq() else 'Unknown'
            }
            
            # å…§å­˜ä¿¡æ¯
            memory = psutil.virtual_memory()
            memory_info = {
                'total': f"{memory.total // (1024**3)}GB",
                'available': f"{memory.available // (1024**3)}GB",
                'used_percent': f"{memory.percent}%"
            }
            
            # ç£ç›¤ä¿¡æ¯
            disk = psutil.disk_usage('.')
            disk_info = {
                'total': f"{disk.total // (1024**3)}GB",
                'free': f"{disk.free // (1024**3)}GB",
                'used_percent': f"{(disk.used / disk.total) * 100:.1f}%"
            }
            
            self.logger.info("ç³»çµ±ä¿¡æ¯:")
            self.logger.info(f"  CPU: {cpu_info['processor']}æ ¸å¿ƒ/{cpu_info['logical_cores']}ç·šç¨‹ @ {cpu_info['frequency']}MHz")
            self.logger.info(f"  å…§å­˜: {memory_info['used_percent']} å·²ä½¿ç”¨ ({memory_info['available']} å¯ç”¨ / {memory_info['total']} ç¸½è¨ˆ)")
            self.logger.info(f"  ç£ç›¤: {disk_info['used_percent']} å·²ä½¿ç”¨ ({disk_info['free']} å¯ç”¨ / {disk_info['total']} ç¸½è¨ˆ)")
            
            if torch.cuda.is_available():
                gpu_name = torch.cuda.get_device_name(0)
                gpu_memory = torch.cuda.get_device_properties(0).total_memory // (1024**3)
                self.logger.info(f"  GPU: {gpu_name} ({gpu_memory}GB)")
            
        except Exception as e:
            self.logger.warning(f"ç²å–ç³»çµ±ä¿¡æ¯å¤±æ•—: {e}")